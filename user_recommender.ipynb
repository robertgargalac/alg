{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "talented-ballet",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import swifter\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selected-format",
   "metadata": {},
   "source": [
    "## 1. Analyze the given data and understand the problem\n",
    "\n",
    "#### 1.1 Identify what attributes are available for both users and questions and their data types\n",
    "#### 1.2 Check for missing values\n",
    "#### 1.3 Check if train questions have only the right answer or if they also contain the uids for those who responded to a specific question\n",
    "#### 1.4 Check if there are users wich had more than 1 \"winner\" answer\n",
    "#### 1.5 Train v.s Test distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nutritional-consolidation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users = pd.read_csv('users.csv')\n",
    "print(df_users.info())\n",
    "df_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-founder",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_questions = pd.read_csv('questions_train.csv')\n",
    "print(df_questions.info())\n",
    "df_questions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "packed-avatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_questions_tst = pd.read_csv('questions_test.csv')\n",
    "print(df_questions_tst.info())\n",
    "df_questions_tst.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-complex",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_missing_fields(df):\n",
    "    percent_missing = df.isnull().sum() * 100 / len(df)\n",
    "    missing_value_df = pd.DataFrame({'column_name': df.columns, 'percent_missing': percent_missing})\n",
    "    print(missing_value_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-desperate",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_missing_fields(df_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-synthesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_missing_fields(df_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-enforcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_missing_fields(df_questions_tst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appreciated-extraction",
   "metadata": {},
   "source": [
    "#### Change date columns from string to date data type\n",
    "    Because date formats are inconsistent (some have miliseconds, some do not, I will use only %Y%m%d format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delayed-event",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_date(datetime_date):\n",
    "    try:\n",
    "        # Split for users dates\n",
    "        date_format, _, _ = datetime_date.split(' ')\n",
    "    except:\n",
    "        # Split for questions dates\n",
    "        date_format, _ = datetime_date.split('T')\n",
    "        \n",
    "    return date_format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-occupation",
   "metadata": {},
   "source": [
    "### Use swifter to optimize the processing speed of apply function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-reader",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users.creation_date = df_users.creation_date.swifter.apply(format_date)\n",
    "df_users.last_access_date = df_users.last_access_date.swifter.apply(format_date)\n",
    "\n",
    "df_questions.date = df_questions.date.swifter.apply(format_date)\n",
    "\n",
    "df_questions_tst.date = df_questions_tst.date.swifter.apply(format_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-garbage",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users.last_access_date = pd.to_datetime(df_users.last_access_date, format='%Y-%m-%d')\n",
    "df_users.creation_date = pd.to_datetime(df_users.creation_date, format='%Y-%m-%d')\n",
    "\n",
    "df_questions.date = pd.to_datetime(df_questions.date, format='%Y-%m-%d')\n",
    "\n",
    "df_questions_tst.date = pd.to_datetime(df_questions_tst.date, format='%Y-%m-%d')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-original",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The oldest user creation date is: {}'.format(df_users.creation_date.min()))\n",
    "print('The most recent user creation date is: {}\\n'.format(df_users.creation_date.max()))\n",
    "\n",
    "print('The oldest question date is: {}'.format(df_questions.date.min()))\n",
    "print('The most recent question date is: {}\\n'.format(df_questions.date.max()))\n",
    "\n",
    "print('The oldest question date for TEST SET is: {}'.format(df_questions_tst.date.min()))\n",
    "print('The most recent question date for TEST SET is: {}'.format(df_questions_tst.date.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assured-invite",
   "metadata": {},
   "source": [
    "#### When I will recommend the top 20 users for a question, I must take into account to not recommend users which did not had an existing account when the question was asked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-dominican",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_questions = len(df_questions)\n",
    "total_unique_questions = len(df_questions.question_id)\n",
    "unique_user_answers = len(df_questions.accepted_answer_id)\n",
    "ownwer_answers_own_question = len(df_questions[df_questions.owner_user_id == df_questions.accepted_answer_id])\n",
    "\n",
    "print('Number of questions is: {}'.format(total_questions))\n",
    "print('Number of unqiue accepted answer ids is: {}'.format(unique_user_answers))\n",
    "print('Number of unique questions is {}'.format(total_unique_questions))\n",
    "print('Numbers of questions where the owner answered to his own question is : {}'.format(ownwer_answers_own_question))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effective-renewal",
   "metadata": {},
   "source": [
    "### Check if count of words distribution is the same for both train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-nursery",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qs = df_questions.text\n",
    "test_qs = df_questions_tst.text\n",
    "\n",
    "# Use a naive word tokenizer, using only space char to create tokens for speed and simplicity\n",
    "word_train = train_qs.apply(lambda x: len(x.split(' ')))\n",
    "word_test = test_qs.apply(lambda x: len(x.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "requested-construction",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.hist(word_train, bins=50, range=[0, 50], color='black', density=True, label='train')\n",
    "plt.hist(word_test, bins=50, range=[0, 50], color='blue',alpha=0.5, density=True, label='test')\n",
    "plt.title('Words probability distributions for question body')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-shield",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_titles = df_questions.title\n",
    "test_titles = df_questions_tst.title\n",
    "\n",
    "# Use a naive word tokenizer, using only space char to create tokens for speed and simplicity\n",
    "title_words_train = train_titles.apply(lambda x: len(x.split(' ')))\n",
    "title_words_test = test_titles.apply(lambda x: len(x.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-green",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.hist(title_words_train, bins=50, range=[0, 50], color='blue', density=True, label='train')\n",
    "plt.hist(title_words_test, bins=50, range=[0, 50], color='red',alpha=0.7, density=True, label='test')\n",
    "plt.legend()\n",
    "plt.title('Words probability distributions for question title')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "soviet-disability",
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud = WordCloud(width = 1200, height= 900).generate(\" \".join(df_questions.text.sample(10000)))\n",
    "\n",
    "plt.figure(figsize=(20, 15))\n",
    "plt.imshow(cloud)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-composer",
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_tst = WordCloud(width = 1200, height= 900).generate(\" \".join(df_questions_tst.text.sample(10000)))\n",
    "\n",
    "plt.figure(figsize=(20, 15))\n",
    "plt.imshow(cloud_tst)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-remove",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "#### For each question we only know what is the accepted answer, but we have no data regarding to other possible answers that were given to a specific question.\n",
    "\n",
    "#### Given this information, it is pretty obvious that a Colaborative Filtering approach will not be suitable for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powerful-bachelor",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis\n",
    "\n",
    "#### 2.1 Compute the time spent on platform for each user\n",
    "#### 2.2 Check distribution for numerical data\n",
    "#### 3.3 See how numerical data change over time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-institute",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users['time_spent_days'] = (df_users['last_access_date'] - df_users['creation_date']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medium-cruise",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-scientist",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution(field):\n",
    "    plot = plt.plot()\n",
    "    plt.hist(df_users[field], bins=30, log=True)\n",
    "    plt.ylabel('Count')\n",
    "    plt.xlabel(field)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lonely-voltage",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_fields = ['reputation', 'up_votes', 'down_votes', 'views', 'time_spent_days']\n",
    "\n",
    "for field in numeric_fields:\n",
    "    plot_distribution(field)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "headed-jackson",
   "metadata": {},
   "source": [
    "#### For ploting the relationship between numerical data and time I will use only a sample of data in order to be efficient in terms of speed\n",
    "#### I will also remove the users which have reputation, up-votes etc. less than 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divine-symposium",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_joint_time(field):\n",
    "    df_plot = df_users[df_users[field] > 1]\n",
    "    sample_data = df_plot.sample(5000)\n",
    "    sns.jointplot(data=sample_data, x='time_spent_days', y=field, kind=\"scatter\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-tissue",
   "metadata": {},
   "outputs": [],
   "source": [
    "for field in numeric_fields:\n",
    "    if field == 'time_spent_days':\n",
    "        continue\n",
    "    plot_joint_time(field)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timely-disco",
   "metadata": {},
   "source": [
    "#### We can see that for each numerical attribute is a tendency to have higher values as the numbers of days grow\n",
    "#### Due to that, in the data processing phase, I will normalize these values based on time spent on the platform by each user. (A user with 100 reputation after 5 days might be just as good (or better) than a user with 500 reputation after 2 years)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "literary-malawi",
   "metadata": {},
   "source": [
    "## 3. Data Processing and Encoding\n",
    "#### 3.1 Fill NaN values\n",
    "#### 3.2 Encode categorical columns into numericals\n",
    "#### 3.3 Scale numerical values\n",
    "#### 3.4 Process text data and encode it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-bolivia",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in df_users.about_me:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategic-faculty",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-activity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-postcard",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-minority",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-anaheim",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustained-cigarette",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-volume",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-story",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
